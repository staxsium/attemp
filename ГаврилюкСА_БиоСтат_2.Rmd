```{r}
install.packages("tidyverse")
install.packages("readxl")
install.packages("Metrics")
install.packages("pROC")
```

```{r}
library(dplyr)
library(readr)
library(tidyverse)
library(readxl)
library(ggplot2)
library(caret)
library(Metrics)
library(pROC)
```

```{r}
setwd("C:\\Users\\Anya\\Desktop\\2 attemp\\Data")
```

```{r}
cancer_data <- read.csv("wisconsin_breast_cancer.csv")
```

##Проверка пропущенных значений

```{r}
summary(cancer_data[, c("radius_mean", "area_mean", "perimeter_mean", "symmetry_mean")])
sum(is.na(cancer_data$radius_mean))
sum(is.na(cancer_data$area_mean))
sum(is.na(cancer_data$perimeter_mean))
sum(is.na(cancer_data$symmetry_mean))

```

```{r}
FEATURES <- c("area_mean", "perimeter_mean", "symmetry_mean")
TARGET <- "radius_mean"
SEED <- 42
TRAIN_RATIO <- 0.8
```

```{r}
compute_metrics <- function(true, pred) {
  data.frame(
    MAE = Metrics::mae(true, pred),
    MSE = Metrics::mse(true, pred),
    RMSE = Metrics::rmse(true, pred),
    R2 = caret::R2(pred, true),
    stringsAsFactors = FALSE
  )
}

```

```{r}
results <- data.frame()

cat("\n====== Linear Regression ======\n")
par(mfrow = c(1, length(FEATURES)))

for (feature in FEATURES) {
  # Prepare data - using cancer_data instead of df
  df_sub <- cancer_data[, c(feature, TARGET)]
  names(df_sub) <- c("X", "Y")
  
  # Train/test split
  set.seed(SEED)
  trainIndex <- createDataPartition(df_sub$Y, p = TRAIN_RATIO, list = FALSE)
  train <- df_sub[trainIndex, ]
  test <- df_sub[-trainIndex, ]
  
  # Train linear model
  model <- lm(Y ~ X, data = train)
  pred <- predict(model, newdata = test)
  
  # Compute metrics
  metrics <- compute_metrics(test$Y, pred)
  metrics$Model <- "Linear"
  metrics$Feature <- feature
  results <- rbind(results, metrics)
  
  # Visualization
  plot(test$X, test$Y, 
       main = paste(feature, "→", TARGET),
       xlab = feature, ylab = TARGET, 
       pch = 16, col = rgb(0, 0, 0, 0.5))
  points(test$X, pred, col = "red", pch = 16)
  legend("topleft", 
         legend = c("Actual", "Predicted"), 
         col = c("black", "red"), pch = 16)
}
```
# Для area_mean и perimeter_mean Линейная регрессия отлично подходит. Можно использовать эти модели для предсказания радиуса. Симметричность не является хорошим предиктором радиуса
```{r}
# Преобразуем диагноз в бинарную переменную
cancer_data$diagnosis <- ifelse(cancer_data$diagnosis == "M", 1, 0)

# Выберем нужные колонки
features <- c("radius_mean", "area_mean", "texture_mean")
target <- "diagnosis"

# Убедимся, что нет пропущенных значений
colSums(is.na(cancer_data[, c(features, target)]))
```
```{r}
set.seed(42)
trainIndex <- createDataPartition(cancer_data$diagnosis, p = 0.8, list = FALSE)
train <- cancer_data[trainIndex, ]
test <- cancer_data[-trainIndex, ]
```
```{r}
train_model <- function(feature, target, train, test) {
  formula <- as.formula(paste(target, "~", feature))
  
  # Обучаем логистическую регрессию
  model <- glm(formula, data = train, family = "binomial")
  
  # Предсказание вероятностей
  prob <- predict(model, newdata = test, type = "response")
  pred <- ifelse(prob > 0.5, 1, 0)
  
  # Матрица ошибок
  cm <- confusionMatrix(as.factor(pred), as.factor(test[[target]]))
  
  # ROC-кривая и AUC (используем pROC)
  roc_obj <- pROC::roc(test[[target]], prob)
  auc_value <- pROC::auc(roc_obj)
  
  # Собираем метрики
  metrics <- data.frame(
    Feature = feature,
    Accuracy = cm$overall["Accuracy"],
    Sensitivity = cm$byClass["Sensitivity"],
    Specificity = cm$byClass["Specificity"],
    AUC = auc_value,
    stringsAsFactors = FALSE
  )
  
  return(metrics)
}
```
```{r}
# Применяем функцию ко всем признакам
results_logistic <- lapply(features, train_model, target, train, test)
results_logistic <- do.call(rbind, results_logistic)

# Визуализация ROC-кривых
par(mfrow = c(1, 3))  # 3 графика в ряд

for (feature in features) {
  formula <- as.formula(paste(target, "~", feature))
  model <- glm(formula, data = train, family = "binomial")
  prob <- predict(model, newdata = test, type = "response")
  roc_obj <- pROC::roc(test[[target]], prob)
  
  plot(roc_obj, main = paste("ROC for", feature), col = "blue")
  legend("bottomright", legend = paste("AUC =", round(pROC::auc(roc_obj), 3)), fill = "blue")
}
```
#radius_mean и area_mean показали наивысшую прогностическую силу, texture_mean работает хуже (AUC ≈ 0.7–0.8), но остаётся значимым предиктором.